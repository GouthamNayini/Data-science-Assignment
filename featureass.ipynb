{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "Min max Scaling is data Transformation Techinque used in the Future Scaling Concept \n",
    "the min max scaler tranforms all the values between range[0,1]\n",
    "formula is x(scaled)=((Xi-Xmin)/(xmax-xmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29157939],\n",
       "       [0.1522832 ],\n",
       "       [0.3757855 ],\n",
       "       [0.43171345],\n",
       "       [0.45077503],\n",
       "       [0.46543779],\n",
       "       [0.11939673],\n",
       "       [0.49874319],\n",
       "       [0.25073314],\n",
       "       [0.24528697],\n",
       "       [0.15081693],\n",
       "       [0.67427734],\n",
       "       [0.25869292],\n",
       "       [0.32174277],\n",
       "       [0.24633431],\n",
       "       [0.38772518],\n",
       "       [0.15207373],\n",
       "       [0.27691663],\n",
       "       [0.29116045],\n",
       "       [0.36824466],\n",
       "       [0.31105991],\n",
       "       [0.36070381],\n",
       "       [0.2660243 ],\n",
       "       [0.761416  ],\n",
       "       [0.35085882],\n",
       "       [0.30875576],\n",
       "       [0.21575199],\n",
       "       [0.20150817],\n",
       "       [0.39023879],\n",
       "       [0.34729786],\n",
       "       [0.13573523],\n",
       "       [0.32006703],\n",
       "       [0.25115207],\n",
       "       [0.36908253],\n",
       "       [0.30812736],\n",
       "       [0.43967323],\n",
       "       [0.27733557],\n",
       "       [0.29032258],\n",
       "       [0.32718894],\n",
       "       [0.59069962],\n",
       "       [0.27167993],\n",
       "       [0.30142438],\n",
       "       [0.22769166],\n",
       "       [0.13845832],\n",
       "       [0.57247591],\n",
       "       [0.31881022],\n",
       "       [0.40134059],\n",
       "       [0.6143695 ],\n",
       "       [0.53372434],\n",
       "       [0.31357352],\n",
       "       [0.19836615],\n",
       "       [0.15123586],\n",
       "       [0.66485128],\n",
       "       [0.14390448],\n",
       "       [0.47109342],\n",
       "       [0.34394638],\n",
       "       [0.73188102],\n",
       "       [0.4888982 ],\n",
       "       [0.17113532],\n",
       "       [0.94679514],\n",
       "       [0.36070381],\n",
       "       [0.22496858],\n",
       "       [0.16652702],\n",
       "       [0.31881022],\n",
       "       [0.30414747],\n",
       "       [0.35630499],\n",
       "       [0.28026812],\n",
       "       [0.        ],\n",
       "       [0.359447  ],\n",
       "       [0.25010473],\n",
       "       [0.18747382],\n",
       "       [0.29325513],\n",
       "       [0.49832426],\n",
       "       [0.46522832],\n",
       "       [0.24423963],\n",
       "       [0.15584416],\n",
       "       [0.31105991],\n",
       "       [0.50544617],\n",
       "       [0.4124424 ],\n",
       "       [0.29786343],\n",
       "       [0.34289904],\n",
       "       [0.28466695],\n",
       "       [0.14662757],\n",
       "       [0.6202346 ],\n",
       "       [0.27042313],\n",
       "       [0.66527021],\n",
       "       [0.20863008],\n",
       "       [0.31860075],\n",
       "       [0.45328865],\n",
       "       [0.37892752],\n",
       "       [0.54252199],\n",
       "       [0.40678676],\n",
       "       [0.05613741],\n",
       "       [0.27754504],\n",
       "       [0.41223293],\n",
       "       [0.7771261 ],\n",
       "       [0.50712191],\n",
       "       [0.18768328],\n",
       "       [0.3757855 ],\n",
       "       [0.19669041],\n",
       "       [0.17343946],\n",
       "       [0.25785505],\n",
       "       [0.86363636],\n",
       "       [0.40532049],\n",
       "       [0.37390029],\n",
       "       [0.25743611],\n",
       "       [0.36489317],\n",
       "       [0.46376204],\n",
       "       [0.31776288],\n",
       "       [0.23544198],\n",
       "       [0.22894847],\n",
       "       [0.0875576 ],\n",
       "       [0.73313783],\n",
       "       [0.43736908],\n",
       "       [0.47423544],\n",
       "       [0.29828236],\n",
       "       [0.56263092],\n",
       "       [0.15877671],\n",
       "       [0.196062  ],\n",
       "       [0.44009217],\n",
       "       [0.18056137],\n",
       "       [0.21679933],\n",
       "       [0.23439464],\n",
       "       [0.26979472],\n",
       "       [0.19710934],\n",
       "       [0.55990783],\n",
       "       [0.11416003],\n",
       "       [0.2398408 ],\n",
       "       [0.17406787],\n",
       "       [0.4136992 ],\n",
       "       [0.33535819],\n",
       "       [0.36028488],\n",
       "       [0.16966904],\n",
       "       [0.19250105],\n",
       "       [0.31818182],\n",
       "       [0.11395057],\n",
       "       [0.15207373],\n",
       "       [0.23209049],\n",
       "       [0.27084206],\n",
       "       [0.21135316],\n",
       "       [0.30163385],\n",
       "       [0.65416841],\n",
       "       [0.79849183],\n",
       "       [0.50230415],\n",
       "       [0.27984918],\n",
       "       [0.11059908],\n",
       "       [0.3261416 ],\n",
       "       [0.1843318 ],\n",
       "       [0.140553  ],\n",
       "       [0.09300377],\n",
       "       [0.23041475],\n",
       "       [0.21072476],\n",
       "       [0.29723502],\n",
       "       [0.44993716],\n",
       "       [0.34981148],\n",
       "       [0.56095517],\n",
       "       [0.94470046],\n",
       "       [0.45936322],\n",
       "       [0.21617093],\n",
       "       [0.28110599],\n",
       "       [0.38604943],\n",
       "       [0.20087977],\n",
       "       [0.27524089],\n",
       "       [0.22496858],\n",
       "       [0.30247172],\n",
       "       [0.44930876],\n",
       "       [0.37054881],\n",
       "       [0.59991621],\n",
       "       [0.1575199 ],\n",
       "       [0.15835777],\n",
       "       [1.        ],\n",
       "       [0.26686217],\n",
       "       [0.0875576 ],\n",
       "       [0.60284876],\n",
       "       [0.28801843],\n",
       "       [0.6248429 ],\n",
       "       [0.3104315 ],\n",
       "       [0.23900293],\n",
       "       [0.13678257],\n",
       "       [0.66108085],\n",
       "       [0.66149979],\n",
       "       [0.42438207],\n",
       "       [0.8856305 ],\n",
       "       [0.42103058],\n",
       "       [0.78508588],\n",
       "       [0.36908253],\n",
       "       [0.37348136],\n",
       "       [0.57373272],\n",
       "       [0.31587767],\n",
       "       [0.41956431],\n",
       "       [0.26434855],\n",
       "       [0.35064935],\n",
       "       [0.53142019],\n",
       "       [0.25994973],\n",
       "       [0.2829912 ],\n",
       "       [0.09405111],\n",
       "       [0.1522832 ],\n",
       "       [0.83870968],\n",
       "       [0.20800168],\n",
       "       [0.21868454],\n",
       "       [0.32760788],\n",
       "       [0.20255551],\n",
       "       [0.20800168],\n",
       "       [0.27922078],\n",
       "       [0.36573104],\n",
       "       [0.28068705],\n",
       "       [0.49266862],\n",
       "       [0.74696271],\n",
       "       [0.44407206],\n",
       "       [0.20297444],\n",
       "       [0.565354  ],\n",
       "       [0.47800587],\n",
       "       [0.94805195],\n",
       "       [0.21365731],\n",
       "       [0.52576456],\n",
       "       [0.205907  ],\n",
       "       [0.52534562],\n",
       "       [0.17846669],\n",
       "       [0.09782153],\n",
       "       [0.56702974],\n",
       "       [0.19040637],\n",
       "       [0.21679933],\n",
       "       [0.11541684],\n",
       "       [0.27042313],\n",
       "       [0.21679933],\n",
       "       [0.2764977 ],\n",
       "       [0.1470465 ],\n",
       "       [0.3640553 ],\n",
       "       [0.21386678],\n",
       "       [0.39903645],\n",
       "       [0.43862589],\n",
       "       [0.26434855],\n",
       "       [0.17888563],\n",
       "       [0.16129032],\n",
       "       [0.26099707],\n",
       "       [0.14662757],\n",
       "       [0.19962296],\n",
       "       [0.62337662],\n",
       "       [0.68621701],\n",
       "       [0.5437788 ],\n",
       "       [0.50502723],\n",
       "       [0.41055718],\n",
       "       [0.30896523],\n",
       "       [0.32907415]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df=sns.load_dataset(\"tips\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm=MinMaxScaler()\n",
    "mm.fit_transform(df[['total_bill']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goutham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0294093]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.transform([[1.666]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "\n",
    "The Unit Vector technique, also known as vector normalization or unit normalization, is a method used in feature scaling to transform numerical features into a common scale without distorting differences in the ranges of values. This technique scales each feature vector component by dividing it by its magnitude (Euclidean norm), resulting in a vector with a length of 1.\n",
    "\n",
    "Here's how the Unit Vector technique differs from Min-Max scaling:\n",
    "\n",
    "Unit Vector Technique:\n",
    "Involves dividing each feature value by the Euclidean norm of the feature vector.\n",
    "It preserves the direction of the data points in the feature space.\n",
    "Useful when the direction of the data points is important rather than their specific magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "\n",
    "PCA, which stands for Principal Component Analysis, is a statistical technique used for dimensionality reduction in data analysis and machine learning. Its primary goal is to reduce the number of variables in a dataset while preserving as much information as possible.\n",
    "\n",
    "Here's how PCA works and its role in dimensionality reduction:\n",
    "\n",
    "Dimensionality Reduction: In datasets with numerous features or variables, some of these variables may be correlated or redundant. High dimensionality can lead to issues such as increased computational complexity, overfitting, and difficulties in visualization. PCA addresses these problems by transforming the original variables into a new set of variables, known as principal components, which are linear combinations of the original variables.\n",
    "\n",
    "Principle Component Analysis:\n",
    "PCA identifies the directions (or axes) in the data that explain the maximum variance. These directions are called principal components.\n",
    "The first principal component accounts for the most significant variance in the data, the second principal component for the second most significant variance, and so on.\n",
    "Each principal component is orthogonal (uncorrelated) to the others.\n",
    "By selecting a subset of the principal components that capture most of the variance, PCA reduces the dimensionality of the dataset while retaining as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    " PCA and feature extraction are closely related concepts. Feature extraction involves transforming raw data into a reduced set of features while retaining relevant information. PCA can be used for feature extraction by identifying the most significant patterns (principal components) in the data and representing the original features in terms of these components.\n",
    "\n",
    "Here's how PCA can be used for feature extraction:\n",
    "Identify Principal Components: PCA analyzes the covariance structure of the data to identify the directions (principal components) that capture the maximum variance.\n",
    "Reduce Dimensionality: After identifying the principal components, we can choose to retain only a subset of them that explains most of the variance in the data. This reduces the dimensionality of the dataset.\n",
    "Transform Data: The original features are projected onto the selected principal components, effectively extracting a new set of features that capture the most important patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "Min-Max scaling is a technique used to scale numerical features to a specific range, typically [0, 1] or [-1, 1]. In the context of preprocessing data for a recommendation system for a food delivery service, you would use Min-Max scaling as follows:\n",
    "\n",
    "Identify Features: Identify the numerical features in the dataset that need to be scaled, such as price, rating, and delivery time.\n",
    "Compute Min-Max Scaling: For each feature, compute the minimum and maximum values in the dataset.\n",
    "Min-Max Scaling formula: x(scaled)=((Xi-Xmin)/(xmax-xmin))\n",
    "Apply Scaling: Apply the Min-Max scaling transformation to each feature, ensuring that the values are scaled to the desired range.\n",
    "Example:\n",
    "Suppose we have a dataset containing the following features for food items: price (ranging from $5 to $20), rating (ranging from 1 to 5), and delivery time (ranging from 10 to 30 minutes). We want to scale these features to the range [0, 1].\n",
    "\n",
    "For price: Scaled_price = (price - 5) / (20 - 5)\n",
    "For rating: Scaled_rating = (rating - 1) / (5 - 1)\n",
    "For delivery time: Scaled_delivery_time = (delivery_time - 10) / (30 - 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "n the context of building a model to predict stock prices using a dataset containing many features such as company financial data and market trends, PCA can be utilized to reduce the dimensionality of the dataset in the following manner:\n",
    "\n",
    "Identify Relevant Features: Start by identifying the relevant features that contribute to predicting stock prices. These features may include various financial metrics (e.g., earnings per share, price-to-earnings ratio), market indicators (e.g., stock market indices, interest rates), and other relevant factors.\n",
    "\n",
    "Standardize Features: Standardize the features to have mean 0 and variance 1 to ensure that all features contribute equally to the PCA.\n",
    "\n",
    "Apply PCA: Apply PCA to the standardized feature matrix. PCA will identify the principal components (linear combinations of the original features) that capture the maximum variance in the dataset.\n",
    "\n",
    "Select Number of Components: Determine the number of principal components to retain based on the cumulative explained variance. Retain enough principal components to capture a significant portion (e.g., 95%) of the total variance in the dataset.\n",
    "\n",
    "Project Data: Project the original dataset onto the selected principal components to obtain the reduced-dimensional dataset.\n",
    "\n",
    "Reducing the dimensionality of the dataset using PCA can help mitigate the curse of dimensionality, improve computational efficiency, and potentially enhance the performance of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "To perform Min-Max scaling on the dataset containing the values [1, 5, 10, 15, 20] and transform them to a range of -1 to 1, follow these steps:\n",
    "\n",
    "Compute Min and Max: Compute the minimum and maximum values in the dataset. In this case, the minimum value is 1, and the maximum value is 20.\n",
    "\n",
    "Apply Min-Max Scaling Formula: Use the Min-Max scaling formula to scale each value to the desired range:\n",
    "Scaled_value=−1+max_value−min_value2×(value−min_value)​\n",
    " \n",
    "Scale Values: Apply the scaling formula to each value in the dataset.\n",
    "\n",
    "For example:\n",
    "\n",
    "For the value 1: Scaled_value = -1 + 2 * (1 - 1) / (20 - 1) = -1\n",
    "For the value 5: Scaled_value = -1 + 2 * (5 - 1) / (20 - 1) ≈ -0.6\n",
    "For the value 10: Scaled_value = -1 + 2 * (10 - 1) / (20 - 1) ≈ 0.2\n",
    "For the value 15: Scaled_value = -1 + 2 * (15 - 1) / (20 - 1) ≈ 0.6\n",
    "For the value 20: Scaled_value = -1 + 2 * (20 - 1) / (20 - 1) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "To perform Feature Extraction using PCA on the dataset containing features [height, weight, age, gender, blood pressure], follow these steps:\n",
    "\n",
    "Standardize Features: Standardize the features (subtract mean and divide by standard deviation) to ensure they have mean 0 and variance 1. This step is essential for PCA.\n",
    "\n",
    "Apply PCA: Apply PCA to the standardized feature matrix. PCA will identify the principal components that capture the maximum variance in the dataset.\n",
    "\n",
    "Select Number of Components: Determine the number of principal components to retain based on the cumulative explained variance or by evaluating the significance of each component. A common approach is to retain principal components that explain a significant portion (e.g., 95%) of the total variance in the dataset.\n",
    "\n",
    "Project Data: Project the original dataset onto the selected principal components to obtain the reduced-dimensional dataset.\n",
    "\n",
    "The number of principal components to retain depends on the desired balance between dimensionality reduction and information retention. Typically, you would retain enough principal components to capture a high percentage of the total variance while avoiding overfitting. In practice, you may experiment with different numbers of principal components and evaluate their impact on model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
